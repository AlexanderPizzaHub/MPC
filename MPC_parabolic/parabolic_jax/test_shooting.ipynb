{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import gt,pde_staff,tools,validation,model\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as opt\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data.dataset as Dataset\n",
    "import torch.utils.data.dataloader as Dataloader\n",
    "from torch.autograd import Variable\n",
    "import pickle as pkl\n",
    "import os\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './results/t3'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "max_iter = 10000\n",
    "val_int = 100\n",
    "bw = 100 \n",
    "iw = 100\n",
    "mu = 100\n",
    "ld = 0.01\n",
    "\n",
    "ctrl_low = -0.5\n",
    "ctrl_high = 0.5\n",
    "\n",
    "delta = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.NNsol_noskip()\n",
    "p = model.NNsol_noskip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "loading data\n",
    "'''\n",
    "\n",
    "with open(\"dataset/5000pts\",'rb') as pfile:\n",
    "    data = pkl.load(pfile)\n",
    "\n",
    "d_c = data['domain']\n",
    "b_c = data['bdry']\n",
    "i_c = data['init']\n",
    "term_c = data['term']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx1 = d_c['0'][:,0].reshape(-1,1)\n",
    "dx2 = d_c['0'][:,1].reshape(-1,1)\n",
    "dt = d_c['0'][:,2].reshape(-1,1)\n",
    "\n",
    "pdx1 = d_c['1'][:,0].reshape(-1,1)\n",
    "pdx2 = d_c['1'][:,1].reshape(-1,1)\n",
    "dpt = d_c['1'][:,2].reshape(-1,1)\n",
    "\n",
    "bx1 = b_c['0'][:,0].reshape(-1,1)\n",
    "bx2 = b_c['0'][:,1].reshape(-1,1)\n",
    "bt = b_c['0'][:,2].reshape(-1,1)\n",
    "\n",
    "ix1 = i_c['0'][:,0].reshape(-1,1)\n",
    "ix2 = i_c['0'][:,1].reshape(-1,1)\n",
    "it = i_c['0'][:,2].reshape(-1,1)\n",
    "\n",
    "tx1 = term_c['0'][:,0].reshape(-1,1)\n",
    "tx2 = term_c['0'][:,1].reshape(-1,1)\n",
    "tt = term_c['0'][:,2].reshape(-1,1)\n",
    "\n",
    "tdx1,tdx2,tdt = tools.from_numpy_to_tensor_with_grad([dx1,dx2,dt])\n",
    "tpdx1,tpdx2,tbx1,tbx2,tix1,tix2,ttx1,ttx2,tdpt,tbt,tit,ttt = tools.from_numpy_to_tensor([pdx1,pdx2,bx1,bx2,ix1,ix2,tx1,tx2,dpt,bt,it,tt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgen = gt.data_gen()\n",
    "init_dat = torch.tensor(dgen.generate(dgen.yinit,i_c['0'])).reshape(-1,1)\n",
    "yd = torch.tensor(dgen.generate(dgen.ydat,term_c['0'])).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 1, loss: 3422.4818716764694\n",
      "At epoch 101, loss: 594.8944287887196\n",
      "At epoch 201, loss: 726.6219725796954\n",
      "At epoch 301, loss: 746.4394728992158\n",
      "At epoch 401, loss: 714.916754898006\n",
      "At epoch 501, loss: 710.9613783999112\n",
      "At epoch 601, loss: 701.981714717208\n",
      "At epoch 701, loss: 690.4123492938235\n",
      "At epoch 801, loss: 675.5770201333246\n",
      "At epoch 901, loss: 655.538063467112\n",
      "At epoch 1001, loss: 626.9772959096647\n",
      "At epoch 1101, loss: 585.0632394715196\n",
      "At epoch 1201, loss: 526.1085519123806\n",
      "At epoch 1301, loss: 455.14937245744875\n",
      "At epoch 1401, loss: 390.5959613054046\n",
      "At epoch 1501, loss: 347.5341523653234\n",
      "At epoch 1601, loss: 324.23281813175663\n",
      "At epoch 1701, loss: 315.55521472114424\n",
      "At epoch 1801, loss: 320.9218220918648\n",
      "At epoch 1901, loss: 338.3324756031284\n",
      "At epoch 2001, loss: 352.53196273236443\n",
      "At epoch 2101, loss: 352.89043782403854\n",
      "At epoch 2201, loss: 341.9960273069597\n",
      "At epoch 2301, loss: 322.6195367768799\n",
      "At epoch 2401, loss: 296.817464125843\n",
      "At epoch 2501, loss: 267.2030214440445\n",
      "At epoch 2601, loss: 237.66109635976255\n",
      "At epoch 2701, loss: 210.3754094870612\n",
      "At epoch 2801, loss: 187.32883200734744\n",
      "At epoch 2901, loss: 169.44955147137364\n",
      "At epoch 3001, loss: 154.62278571993753\n",
      "At epoch 3101, loss: 140.92993480987388\n",
      "At epoch 3201, loss: 127.15890216107216\n",
      "At epoch 3301, loss: 113.04677232411723\n",
      "At epoch 3401, loss: 98.83552857989996\n",
      "At epoch 3501, loss: 84.66942390932194\n",
      "At epoch 3601, loss: 71.02510003956706\n",
      "At epoch 3701, loss: 58.46958360946178\n",
      "At epoch 3801, loss: 47.8058984019406\n",
      "At epoch 3901, loss: 39.14180523097365\n",
      "At epoch 4001, loss: 32.49560965024589\n",
      "At epoch 4101, loss: 27.423642434261748\n",
      "At epoch 4201, loss: 23.72147616634909\n",
      "At epoch 4301, loss: 21.014377259293525\n",
      "At epoch 4401, loss: 19.032720461772534\n",
      "At epoch 4501, loss: 17.540663626334428\n",
      "At epoch 4601, loss: 16.34933282588517\n",
      "At epoch 4701, loss: 15.381999223454486\n",
      "At epoch 4801, loss: 14.567340115947523\n",
      "At epoch 4901, loss: 13.850244094205136\n",
      "At epoch 5001, loss: 13.242159609520824\n",
      "At epoch 5101, loss: 12.697587232364388\n",
      "At epoch 5201, loss: 12.209119872872582\n",
      "At epoch 5301, loss: 11.782798528805428\n",
      "At epoch 5401, loss: 11.389802499863361\n",
      "At epoch 5501, loss: 11.027232131728828\n",
      "At epoch 5601, loss: 10.709422958484238\n",
      "At epoch 5701, loss: 10.406417687491269\n",
      "At epoch 5801, loss: 10.124413366820702\n",
      "At epoch 5901, loss: 9.870709093155723\n",
      "At epoch 6001, loss: 9.62739627427039\n",
      "At epoch 6101, loss: 9.395329480097146\n",
      "At epoch 6201, loss: 9.184861338625275\n",
      "At epoch 6301, loss: 8.984759545310936\n",
      "At epoch 6401, loss: 8.786578819946067\n",
      "At epoch 6501, loss: 8.602998007180044\n",
      "At epoch 6601, loss: 8.42605187141878\n",
      "At epoch 6701, loss: 8.253715552122504\n",
      "At epoch 6801, loss: 8.08029944963324\n",
      "At epoch 6901, loss: 7.925955124359182\n",
      "At epoch 7001, loss: 7.77397925209259\n",
      "At epoch 7101, loss: 7.619827650482385\n",
      "At epoch 7201, loss: 8.02256904311391\n",
      "At epoch 7301, loss: 7.325313399590985\n",
      "At epoch 7401, loss: 7.186135905829999\n",
      "At epoch 7501, loss: 7.043894251268972\n",
      "At epoch 7601, loss: 6.897849811656631\n",
      "At epoch 7701, loss: 6.7701261859394\n",
      "At epoch 7801, loss: 6.640882898184163\n",
      "At epoch 7901, loss: 6.510080244505824\n",
      "At epoch 8001, loss: 6.375133225495472\n",
      "At epoch 8101, loss: 6.3320567257976474\n",
      "At epoch 8201, loss: 6.119130217280933\n",
      "At epoch 8301, loss: 5.996669413214463\n",
      "At epoch 8401, loss: 5.870270366828304\n",
      "At epoch 8501, loss: 5.739804237293949\n",
      "At epoch 8601, loss: 5.614546270038729\n",
      "At epoch 8701, loss: 5.502051518416482\n",
      "At epoch 8801, loss: 5.387141971232768\n",
      "At epoch 8901, loss: 5.268821651668909\n",
      "At epoch 9001, loss: 5.147238288871007\n",
      "At epoch 9101, loss: 5.03402524018989\n",
      "At epoch 9201, loss: 4.927002583144267\n",
      "At epoch 9301, loss: 4.8175976331888695\n",
      "At epoch 9401, loss: 4.705614675262233\n",
      "At epoch 9501, loss: 4.894639649034176\n",
      "At epoch 9601, loss: 4.511689651898599\n",
      "At epoch 9701, loss: 4.427898105209431\n",
      "At epoch 9801, loss: 4.343353896171079\n",
      "At epoch 9901, loss: 4.291866885474371\n",
      "At epoch 10001, loss: 5.419964485932441\n",
      "At epoch 10101, loss: 4.566996033069669\n",
      "At epoch 10201, loss: 4.385086628823189\n",
      "At epoch 10301, loss: 4.2569929989342254\n",
      "At epoch 10401, loss: 4.170714753603091\n",
      "At epoch 10501, loss: 4.083223748215795\n",
      "At epoch 10601, loss: 3.990532914922163\n",
      "At epoch 10701, loss: 3.929612713571003\n",
      "At epoch 10801, loss: 3.860774594653118\n",
      "At epoch 10901, loss: 3.7688035945345795\n",
      "At epoch 11001, loss: 3.6992709790937592\n",
      "At epoch 11101, loss: 3.6187273136543507\n",
      "At epoch 11201, loss: 3.840039330423116\n",
      "At epoch 11301, loss: 3.4862278261436743\n",
      "At epoch 11401, loss: 3.4406387434969745\n",
      "At epoch 11501, loss: 3.3894921671449127\n",
      "At epoch 11601, loss: 3.350406063087099\n",
      "At epoch 11701, loss: 3.35348687409619\n",
      "At epoch 11801, loss: 3.248783993096071\n",
      "At epoch 11901, loss: 3.1679510714336705\n",
      "At epoch 12001, loss: 3.124456210629732\n",
      "At epoch 12101, loss: 3.0678032982011256\n",
      "At epoch 12201, loss: 3.0265654180855606\n",
      "At epoch 12301, loss: 2.986572037845731\n",
      "At epoch 12401, loss: 2.945323775060888\n",
      "At epoch 12501, loss: 2.9017139881798517\n",
      "At epoch 12601, loss: 2.876791455840652\n",
      "At epoch 12701, loss: 3.1345270985543743\n",
      "At epoch 12801, loss: 3.092750108246957\n",
      "At epoch 12901, loss: 2.80358547090323\n",
      "At epoch 13001, loss: 2.760944856817515\n",
      "At epoch 13101, loss: 2.709201735676604\n",
      "At epoch 13201, loss: 2.6787608687443547\n",
      "At epoch 13301, loss: 2.6503523657386054\n",
      "At epoch 13401, loss: 2.6217774079664147\n",
      "At epoch 13501, loss: 2.5975404392511456\n",
      "At epoch 13601, loss: 2.566534549564059\n",
      "At epoch 13701, loss: 2.53929568859467\n",
      "At epoch 13801, loss: 2.510966252672808\n",
      "At epoch 13901, loss: 2.4842278655241024\n",
      "At epoch 14001, loss: 2.462275448007049\n",
      "At epoch 14101, loss: 2.506362353345085\n",
      "At epoch 14201, loss: 2.812210438115555\n",
      "At epoch 14301, loss: 2.6580669144913065\n",
      "At epoch 14401, loss: 2.395709667315368\n",
      "At epoch 14501, loss: 2.475848028101605\n",
      "At epoch 14601, loss: 2.3290083041725063\n",
      "At epoch 14701, loss: 2.313153275153008\n",
      "At epoch 14801, loss: 2.291345404230579\n",
      "At epoch 14901, loss: 2.2716418617648975\n",
      "At epoch 15001, loss: 2.2542830626520125\n",
      "At epoch 15101, loss: 2.234870078982257\n",
      "At epoch 15201, loss: 2.216631800250337\n",
      "At epoch 15301, loss: 2.1976918180180616\n",
      "At epoch 15401, loss: 2.179319848189322\n",
      "At epoch 15501, loss: 2.159492030830104\n",
      "At epoch 15601, loss: 2.145187766415049\n",
      "At epoch 15701, loss: 2.356435507605058\n",
      "At epoch 15801, loss: 2.4184977986236733\n",
      "At epoch 15901, loss: 2.2584808622751744\n",
      "At epoch 16001, loss: 2.1108364946978173\n"
     ]
    }
   ],
   "source": [
    "bdry_dat = torch.zeros_like(tbx1)\n",
    "adj_pdata = torch.zeros_like(tdx1)\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "class recorder():\n",
    "    def __init__(self):\n",
    "        self.losslist = [] \n",
    "        self.epoch = 0 \n",
    "\n",
    "    def hook(self,optimizer,nploss):\n",
    "        self.epoch += 1 \n",
    "        self.losslist.append(nploss)\n",
    "\n",
    "        if self.epoch % 100 == 1:\n",
    "            print(\"At epoch {}, loss: {}\".format(self.epoch,nploss))\n",
    "            validation.plot_t(y,path+\"/y.png\",t=1.0)\n",
    "            validation.plot_t(p,path+\"/p.png\",t=1.0)\n",
    "        \n",
    "rec = recorder()\n",
    "\n",
    "params = list(y.parameters())+list(p.parameters())\n",
    "#optimizer = opt.LBFGS(params,line_search_fn='strong_wolfe',max_iter=max_iter,tolerance_grad=1e-20,tolerance_change=1e-20,stephook=rec.hook)\n",
    "optimizer = opt.Adam(params,lr=1e-4)\n",
    "\n",
    "pred_ind = 0\n",
    "\n",
    "def lossfunc(pde_data,adj_tdata):\n",
    "    \n",
    "    ploss, _, _ = pde_staff.pdeloss(y,tdx1,tdx2,tdt,pde_data,tbx1,tbx2,tbt,bdry_dat,tix1,tix2,tit,init_dat,bw,iw)\n",
    "    aloss, _, _ = pde_staff.adjloss(p,tdx1,tdx2,tdt,adj_pdata,tbx1,tbx2,tbt,bdry_dat,ttx1,ttx2,ttt,adj_tdata,bw,iw)\n",
    "\n",
    "    loss_couple = ploss + mu*aloss \n",
    "    return loss_couple\n",
    "\n",
    "def train(predomain_data = None):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            adj_tdata = y(ttx1,ttx2,ttt)-yd\n",
    "            pde_data = model.projection_clamp(- p(tdx1,tdx2,tdt)/ld,ctrl_low,ctrl_high)\n",
    "        loss_couple = lossfunc(pde_data,adj_tdata)\n",
    "\n",
    "        if predomain_data is not None:\n",
    "            loss_pre = mse_loss(predomain_data,y(tpdx1,tpdx2,tdpt))\n",
    "        else:\n",
    "            loss_pre = 0.\n",
    "\n",
    "        loss = loss_couple + loss_pre\n",
    "        loss.backward()\n",
    "        return loss.detach().numpy()\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        nploss = closure()\n",
    "        optimizer.step()\n",
    "        rec.hook(optimizer,nploss)\n",
    "    \n",
    "\n",
    "\n",
    "train()\n",
    "validation.plot_t(y,path+\"/y_pred{}.png\".format(pred_ind))\n",
    "for i in range(9):\n",
    "    with torch.no_grad():\n",
    "        predomain_data = y(tpdx1,tpdx2,tdpt+delta)\n",
    "        init_data = y(tix1,tix2,tit+delta)\n",
    "    train(predomain_data)\n",
    "    pred_ind += 1\n",
    "    validation.plot_t(y,path+\"/y_pred{}.png\".format(pred_ind),t=1.0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
